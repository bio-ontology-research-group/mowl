{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Onto2Vec\n\nThis example corresponds to the paper [Onto2Vec: joint vector-based representation of biological entities and their ontology-based annotations](https://doi.org/10.1093/bioinformatics/bty259). \n\nThis method is an approach to learn numerical representations (embeddings) of (biomedical) ontologies by representing ontology axioms as text sequences and applying an unsupervised learning algorithm such as Word2Vec. Onto2Vec uses an ontology reasoner to infer new axioms as \na preprocessing step. The algorithm is tested on the protein-protein interaction task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this algorithm, we need three components:\n\n- The reasoner\n- The corpus generator\n- The Word2Vec model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mowl\nmowl.init_jvm(\"20g\")\n\nfrom mowl.datasets.builtin import PPIYeastSlimDataset\nfrom mowl.corpus import extract_and_save_axiom_corpus\nfrom mowl.owlapi import OWLAPIAdapter\nfrom mowl.reasoning import MOWLReasoner\n\nfrom org.semanticweb.elk.owlapi import ElkReasonerFactory\nfrom java.util import HashSet\n\nfrom gensim.models.word2vec import LineSentence\nfrom gensim.models import Word2Vec\n\nimport os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inferring new axioms\n\nOnto2Vec uses an ontology reasoner to infer new axioms as a preprocessing step. In the original\npaper, the authors used the HermiT reasoner. For this example, we use the ELK reasoner.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = PPIYeastSlimDataset()\n\nreasoner_factory = ElkReasonerFactory()\nreasoner = reasoner_factory.createReasoner(dataset.ontology)\nmowl_reasoner = MOWLReasoner(reasoner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We wrap the reasoner into the :class:`MOWLReasoner <mowl.reasoning.base.MOWLReasoner>` class \\\nin order to use some shortcuts the mOWL\nprovides such as:\n\n- inferring subclass axioms\n- inferring equivalent class axioms\n- inferring disjoint axioms (not applicable for this example since we use ELK reasoner)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classes = dataset.ontology.getClassesInSignature()\nsubclass_axioms = mowl_reasoner.infer_subclass_axioms(classes)\nequivalent_class_axioms = mowl_reasoner.infer_equivalent_class_axioms(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now add the inferred axioms to the ontology.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adapter = OWLAPIAdapter()\nmanager = adapter.owl_manager\n\naxioms = HashSet()\naxioms.addAll(subclass_axioms)\naxioms.addAll(equivalent_class_axioms)\n\nmanager.addAxioms(dataset.ontology, axioms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating the corpus and training the model\n\nNow that we have an extended ontology, we can generate the corpus out of it. After that, we\ncan train the Word2Vec model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "extract_and_save_axiom_corpus(dataset.ontology, \"onto2vec_corpus.txt\")\n\nsentences = LineSentence(\"onto2vec_corpus.txt\")\nmodel = Word2Vec(sentences, vector_size=5, window=2, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cleaning up memory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "os.remove(\"onto2vec_corpus.txt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}